{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import json\n",
    "import re\n",
    "r = '[）\\（\\·\\，\\。\\“ \\”\\?\\？\\」\\「\\…\\、\\《\\》\\；\\)\\(\\.\\(\\/\\)\\”\\“\\—]'\n",
    "data = []\n",
    "endata = []\n",
    "chdata = []\n",
    "\n",
    "for line in open('test.txt', 'r', encoding='utf-8'):\n",
    "    # val = re.sub(r,' ',line)\n",
    "    data.append(json.loads(line))  \n",
    "    \n",
    "print('----------')\n",
    "\n",
    "for i in range(len(data)):\n",
    "    endata.append(data[i]['english'])\n",
    "    chdata.append(data[i]['chinese'])\n",
    "\n",
    "en_vocab = set(''.join(endata))\n",
    "id2en = list(en_vocab)\n",
    "en2id = {c:i for i,c in enumerate(id2en)}\n",
    "\n",
    "# 分別生成中英文字典\n",
    "ch_vocab = set(''.join(chdata))\n",
    "id2ch = list(ch_vocab)\n",
    "ch2id = {c:i for i,c in enumerate(id2ch)}\n",
    "\n",
    "# print('英文數據:\\n', endata)\n",
    "# print('\\n中文數據:\\n', chdata)\n",
    "print('\\n英文字典:\\n', en2id)\n",
    "print('\\n中文字典共計\\n:', ch2id)\n",
    "\n",
    "\n",
    "# en_vocab = set(''.join(endata))\n",
    "# id2en = list(en_vocab)\n",
    "# en2id = {c:i for i,c in enumerate(id2en)}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------\n",
      "\n",
      "英文字典:\n",
      " {'e': 0, 'u': 1, 'W': 2, '0': 3, '3': 4, ':': 5, \"'\": 6, '“': 7, '—': 8, 'x': 9, 'G': 10, 'm': 11, 'F': 12, 'K': 13, 'l': 14, 'o': 15, 'i': 16, '1': 17, 'y': 18, 'M': 19, 'z': 20, 'H': 21, '2': 22, 'd': 23, 'f': 24, 'A': 25, 'E': 26, '…': 27, 's': 28, '\"': 29, 'C': 30, '(': 31, 'r': 32, ',': 33, 'L': 34, '.': 35, ')': 36, 'b': 37, 'P': 38, 'v': 39, 'c': 40, 'k': 41, 'a': 42, 'I': 43, '6': 44, 'h': 45, '-': 46, 'n': 47, 'J': 48, 'N': 49, 'B': 50, '?': 51, 'T': 52, '7': 53, ' ': 54, 't': 55, '/': 56, 'g': 57, 'p': 58, 'w': 59}\n",
      "\n",
      "中文字典共計\n",
      ": {'去': 0, '0': 1, '球': 2, '的': 3, '继': 4, '但': 5, '使': 6, '指': 7, '荐': 8, '推': 9, '为': 10, '配': 11, '将': 12, '己': 13, '杰': 14, '名': 15, '处': 16, '烈': 17, '相': 18, '亲': 19, '谓': 20, '姬': 21, '确': 22, '和': 23, '液': 24, '粒': 25, '金': 26, '活': 27, '塞': 28, '影': 29, '稀': 30, '马': 31, '录': 32, '：': 33, '前': 34, '队': 35, '喜': 36, '爱': 37, '锐': 38, '6': 39, '靠': 40, '想': 41, '大': 42, '还': 43, '所': 44, '他': 45, '往': 46, '汽': 47, '讽': 48, '主': 49, '里': 50, '电': 51, '钱': 52, '竟': 53, '微': 54, '擎': 55, '—': 56, '日': 57, '子': 58, '先': 59, '年': 60, '作': 61, '斯': 62, '以': 63, '着': 64, '姆': 65, '析': 66, '白': 67, '亚': 68, '自': 69, '真': 70, '2': 71, '朵': 72, '车': 73, '星': 74, '释': 75, '耳': 76, '…': 77, '娜': 78, '称': 79, '新': 80, '视': 81, '从': 82, '音': 83, '族': 84, '克': 85, '些': 86, '道': 87, '记': 88, '宣': 89, '月': 90, '歧': 91, '欢': 92, '通': 93, '蒂': 94, '擦': 95, '东': 96, '此': 97, '沃': 98, '好': 99, '”': 100, '要': 101, '礼': 102, '德': 103, '战': 104, '探': 105, '种': 106, '造': 107, '这': 108, '二': 109, '中': 110, '它': 111, '书': 112, '山': 113, '上': 114, '引': 115, '未': 116, '生': 117, '风': 118, '酷': 119, '把': 120, '过': 121, '化': 122, '鲜': 123, '后': 124, '丁': 125, '城': 126, '控': 127, '人': 128, '是': 129, '福': 130, '分': 131, '设': 132, '挑': 133, '与': 134, '铜': 135, '玛': 136, '1': 137, '度': 138, '剂': 139, '部': 140, '地': 141, '可': 142, '来': 143, '鞋': 144, '会': 145, '天': 146, '律': 147, '皮': 148, '定': 149, '们': 150, '绿': 151, '抚': 152, '路': 153, '吉': 154, '历': 155, '针': 156, '排': 157, '到': 158, '一': 159, '附': 160, '我': 161, '片': 162, '思': 163, '成': 164, '流': 165, '特': 166, '猿': 167, '3': 168, '》': 169, '·': 170, '“': 171, '母': 172, '血': 173, '《': 174, '最': 175, '湖': 176, '父': 177, '长': 178, '遭': 179, '。': 180, '睦': 181, '底': 182, '近': 183, '结': 184, '讥': 185, '婚': 186, '给': 187, '更': 188, '尔': 189, '，': 190, '用': 191, '显': 192, '了': 193, '同': 194, '扬': 195, '颗': 196, '第': 197, '多': 198, '个': 199, '渣': 200, '对': 201, '在': 202, '贫': 203, '冰': 204, '带': 205, '交': 206}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "en_num_data = [[en2id[en] for en in line ] for line in endata]\n",
    "ch_num_data = [[ch2id[ch] for ch in line] for line in chdata]\n",
    "de_num_data = [[ch2id[ch] for ch in line][1:] for line in chdata]\n",
    "\n",
    "print('char:', endata[1])\n",
    "print('index:', en_num_data[1])\n",
    "# de_num_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "char: He calls the Green Book, his book of teachings, “the new gospel.\n",
      "index: [21, 0, 54, 40, 42, 14, 14, 28, 54, 55, 45, 0, 54, 10, 32, 0, 0, 47, 54, 50, 15, 15, 41, 33, 54, 45, 16, 28, 54, 37, 15, 15, 41, 54, 15, 24, 54, 55, 0, 42, 40, 45, 16, 47, 57, 28, 33, 54, 7, 55, 45, 0, 54, 47, 0, 59, 54, 57, 15, 28, 58, 0, 14, 35]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "import numpy as np\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in en_num_data])\n",
    "max_decoder_seq_length = max([len(txt) for txt in ch_num_data])\n",
    "print('max encoder length:', max_encoder_seq_length)\n",
    "print('max decoder length:', max_decoder_seq_length)\n",
    "\n",
    "# 將數據進行onehot處理\n",
    "encoder_input_data = np.zeros((len(en_num_data), max_encoder_seq_length, len(en2id)), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "\n",
    "for i in range(len(ch_num_data)):\n",
    "    for t, j in enumerate(en_num_data[i]):\n",
    "        encoder_input_data[i, t, j] = 1.\n",
    "    for t, j in enumerate(ch_num_data[i]):\n",
    "        decoder_input_data[i, t, j] = 1.\n",
    "    for t, j in enumerate(de_num_data[i]):\n",
    "        decoder_target_data[i, t, j] = 1.\n",
    "\n",
    "print('index data:\\n', en_num_data[1])\n",
    "print('one hot data:\\n', encoder_input_data[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[52, 45, 0, 54, 11, 42, 55, 55, 0, 54, 42, 28, 54, 11, 42, 16, 47, 54, 40, 15, 58, 58, 0, 32, 54, 58, 45, 42, 28, 0, 54, 16, 47, 54, 55, 45, 0, 54, 40, 14, 0, 42, 47, 16, 47, 57, 35, 54, 28, 14, 42, 57, 54, 59, 42, 28, 54, 23, 0, 55, 0, 32, 46, 54, 11, 16, 47, 0, 23, 54, 37, 18, 54, 0, 14, 0, 40, 55, 32, 15, 47, 54, 58, 32, 15, 37, 0, 54, 11, 16, 40, 32, 15, 28, 40, 15, 58, 16, 40, 54, 42, 47, 42, 14, 18, 28, 16, 28, 35]\n",
      "max encoder length: 165\n",
      "max decoder length: 63\n",
      "index data:\n",
      " [21, 0, 54, 40, 42, 14, 14, 28, 54, 55, 45, 0, 54, 10, 32, 0, 0, 47, 54, 50, 15, 15, 41, 33, 54, 45, 16, 28, 54, 37, 15, 15, 41, 54, 15, 24, 54, 55, 0, 42, 40, 45, 16, 47, 57, 28, 33, 54, 7, 55, 45, 0, 54, 47, 0, 59, 54, 57, 15, 28, 58, 0, 14, 35]\n",
      "one hot data:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}